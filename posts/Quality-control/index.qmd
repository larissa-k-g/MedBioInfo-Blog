---
title: "Quality control"
author: "Larissa Kahnwald"
date: "2025-10-07"
categories: [news]
---
![](DNA.jpg){style="float:right; width:45%; margin:0 0 1rem 1rem;"}  

Determining the quality of your data is key, in order to know if your result is trustworthy or not, should you actually be drawing any conlcusions from your experiment in the first place?  
Quaility control is therefore central, to get to know your data and to understand what you are working with. For sequencing data we can use the software FastQC to check the raw data, before starting a lengthy analysis.  
FastQC is especially valuable if we do high-thoughput sequencing and thus have a lot of data to juggle. A lot of data also means that analysis, even if automised might run for several hours, even on a supercomputer. To protect our session from being interupted due to connection issues or because the laptop is accidentally being closed; we can use GNU Screen, a terminal multiplexer. Screen enables to start several independant sessions and even to continue a running process if we disconnect. It basically creates virtual terminals inside our session. Another system we need is a job scheduler. SLURM is such a management system, meaning that it can start and control jobs for you. It is used in computer clusters to organize the queing of different jobs and SLURM also automatically substracts the running time from your project account. So, now that we have our job secured with a screen session and Slurm takes care of the resources we can move on to set the quality control.  
The best way to keep track of all the instructions is to define them in sequence in a script. To this end we create a new directory for all the scripts within our project folder and create a *.sh* file. Since SLURM is our resoource management we use sbatch to submit our batch script.

#### Screen Session
1. Start by naming a session  
`$screen -S name` 
2. Start your process, then detach from the screen any time and let it run independently. You can then log out or start toher screens and come back to this process at a later time.  
`Ctrl+ a d`  
3. Simply get a list of all open screen session:  
`$screen -ls`  
Then, reattach to the selected session:  
`$screen -r name`  

#### Slurm  
You can run Slurm from the command line using:  
`$srun -A project_ID -t dd-hh:mm:ss -n 1 <tool options, commands and pathways to the dataset>`
 <p style="margin-left:2em;"> -> the project_ID defines the project/account which is charged for the computing time  
 <p style="margin-left:2em;"> -> -t gives an estimate of the computing time that the job is going to need. This will not only influence the job queueing (shorter run times are preferred) but also defines the max time that will be spent on the task. After the given time the job will be cancelled.  
    
#### sbatch  
1. Create a new folder within your project folder and add a `.sh` file for the batch script.
2. Set your header similar to this:  
`$ #! /bin/bash -l  
#SBATCH -A project_ID  
#SBATCH -t 30:00  
#SBATCH -n 1  

fastqc -o ../fastqc --noextract ../data/*fastq.gz`  