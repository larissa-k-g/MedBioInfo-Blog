---
title: "Quality control"
author: "Larissa Kahnwald"
date: "2025-10-08"
categories: [news]
---
![](DNA.jpg){style="float:right; width:45%; margin:0 0 1rem 1rem;"}  

Determining the quality of your data is key, in order to know if your result is trustworthy or not, should you actually be drawing any conlcusions from your experiment in the first place?  
Quaility control is therefore central, to get to know your data and to understand what you are working with. For sequencing data we can use the software FastQC to check the raw data, before starting a lengthy analysis.  
FastQC is especially valuable if we do high-thoughput sequencing and thus have a lot of data to juggle. A lot of data also means that analysis, might run for several hours, even on a supercomputer. To protect your session from being interupted due to connection issues or because the laptop is accidentally being closed; we can use GNU Screen, a terminal multiplexer. Screen enables to start several independant sessions and even to continue a running process if we disconnect. It basically creates virtual terminals inside our session. Another system we need is a job scheduler. SLURM is such a management system, meaning that it can start and control jobs for you. It is used in computer clusters to organize the queing of different jobs and SLURM also automatically substracts the running time from your project account. So, now that we have our job secured with a screen session and Slurm takes care of the resources we can move on to set the quality control.  
The best way to keep track of all the instructions is to define them in sequence in a script. To this end, create a new directory for all the scripts within our project folder and create a *.sh* file for our instructions. Since SLURM is our resoource management we use sbatch to submit a batch script.    
To do a quality control for your seqeuncing data you can use FastQC. FastQC is a tool, that is suitable for high-throughput sequencing data. It provides information on the general quality on your reads, visualizes the quiality score distribution, as well as the share of each base per sequence. Using FastQC will allow you to identify contaminations due to adapters or other sequences which are overrepresented. It will give you a quality score for an entire sample, instead of single reads. However, the output will still be one file per sample. Therefore, if you need to analyze several samples in one project you can use MultiQC to summerize the output from FastQC.

#### Screen Session
1. Start by naming a session  
`$screen -S name` 
2. Start your process, then detach from the screen any time and let it run independently. You can then log out or start toher screens and come back to this process at a later time.  
`Ctrl+ a d`  
3. Simply get a list of all open screen session:  
`$screen -ls`  
Then, reattach to the selected session:  
`$screen -r name`   

#### FastQC
1. Use Pixi to install FastQC or check if it has already been installed:  
- to check if it is installed: `$ pixi run fastqc --help`
- to install:  
`$pixi init -c conda-forge -c bioconda`   
`$pixi add fastqc`   
`$pixi run fastqc --help`  

#### MultiQC  
1. Use Pixi to install MultiQC or check if it has already been installed:  
- to check if it is installed fo into the pixi.toml or run `$pixi run multiqc --help`
- to install:  
`$pixi init -c conda-forge -c bioconda`   
`$pixi add multiqc`    

-> To activate the environment run: `$pixi shell`  

#### Slurm  
You can run Slurm from the command line using:  
`$srun -A project_ID -t dd-hh:mm:ss -n 1 <tool options, commands and pathways to the dataset>`  
 - The project_ID defines the project/account which is charged for the computing time. You can check the projects of which you are a member with `$projinfo`. This will also allow you to see how many computing hours are left on them.  
 - '-t' gives an estimate of the computing time that the job is going to need. This will not only influence the job queueing (shorter run times are preferred) but also defines the max time that will be spent on the task. After the given time the job will be cancelled.  
 - to use e.g. FastQC on one or two samples we would define it like this: `$srun -A project_ID -t 15:00 -n 1 fastqc --noextract -o fastqc data/sample_1.fastq.gz data/sample_2.fastq.gz `  

#### sbatch  
1. Create a new folder within your project folder and add a `name.sh` file for the batch script.
2. For FastQC set your file up like this:  
```bash
#!/bin/bash -l 
#SBATCH -A project_ID 
#SBATCH -t dd-hh:mm:ss
#SBATCH -n 1 

pixi run fastqc -o ../fastqc --noextract ../data/*fastq.gz
```
2'. For MultiQC set it up like this  
```bash
#! /bin/bash -l
#SBATCH -A project_ID
#SBATCH -t dd-hh:mm:ss
#SBATCH -n 1

pixi run multiqc -o ../multiqc ../fastqc
```
3. Save the script and run it with pixi:   
`$pixi run sbatch name.sh`  
<p style="margin-left:2em;"> -> you can verify that everything is running properly by checking your job's status: `$ squeue -u <user-name>`   

4. When the job is completed you can find the output files in the same folder, where you where in, when you submitted the job. Per default FastQC and MultiQC will give out an .html file which you can download and open locally.   

#### Containers  
To use FastQC in containers set up your script like this:  
```bash
#! /bin/bash -l
#SBATCH -A hpc2n2025-203
#SBATCH -t 30:00
#SBATCH -n 1

apptainer exec -B ../data/:/data ../container-image/fastqc:0.12.1.sif fastqc -o ../fastqc-container --noextract ../data/*fastq.gz
```   
For more details, on how to get started with containers see my previous post on [Work environments and Containers](https://larissa-k-g.github.io/MedBioInfo-Blog/posts/pixi-environment-containers/).  