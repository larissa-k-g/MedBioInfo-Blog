<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>Applied-Bioinfo-Blog</title>
<link>https://larissa-k-g.github.io/MedBioInfo-Blog/</link>
<atom:link href="https://larissa-k-g.github.io/MedBioInfo-Blog/index.xml" rel="self" type="application/rss+xml"/>
<description>A blog built with Quarto</description>
<generator>quarto-1.8.25</generator>
<lastBuildDate>Wed, 08 Oct 2025 00:00:00 GMT</lastBuildDate>
<item>
  <title>Getting started with nextflow</title>
  <dc:creator>Larissa Kahnwald</dc:creator>
  <link>https://larissa-k-g.github.io/MedBioInfo-Blog/posts/nextflow-introduction/</link>
  <description><![CDATA[ 





<p><img src="https://larissa-k-g.github.io/MedBioInfo-Blog/posts/nextflow-introduction/pipelines.jpg" class="img-fluid" style="float:right; width:45%; margin:0 0 1rem 1rem;"></p>
<p>Nextflow creates a pipeline allowing you to resume from the point of error if something happens during your process. It comes with build-in git version control and allows any code language. They can run containers as well, which eliminates the need to install softwares or running into version and environments conflict. On NF you can find different modules to put in your pipeline. Command line has the highest priority, more details to hierachy on canvas pixi run nextflow run hello.nf -resume –greeting ‘Bonjour le monde!’ does then</p>



 ]]></description>
  <category>news</category>
  <guid>https://larissa-k-g.github.io/MedBioInfo-Blog/posts/nextflow-introduction/</guid>
  <pubDate>Wed, 08 Oct 2025 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Work environments and Containers</title>
  <dc:creator>Larissa Kahnwald</dc:creator>
  <link>https://larissa-k-g.github.io/MedBioInfo-Blog/posts/pixi-environment-containers/</link>
  <description><![CDATA[ 





<p><img src="https://larissa-k-g.github.io/MedBioInfo-Blog/posts/pixi-environment-containers/pixi2025-10-07.png" class="img-fluid" style="float:right; width:45%; margin:0 0 1rem 1rem;"></p>
<p>In science reproducibility and accessibility are two key factors. This does not only apply during the data collection phase of a project but particularly also during its analyisis. To ensure that the same script runs the same way anywhere else we can use environments and containers. That sounds great, but what does that mean? Environments are like isolated spaces where you can install all the tools and packages that you need for a specific analysis. It’s basically like a lab bench that you set up with everything you need, chemicals, pipettes etc. for a specific experiment. Environment managers, such as <strong>Pixi</strong>, make it possible to have multiple different set ups right next to eachother, without one spilling over to the other one and even support you in finding the tools that you want. Containers on the other hand are like a bench on wheels. They contain everything tools, chemicals, hoods, chairs, the bench itself the protocol etc. They are easily shareable and the next person can just open them and run the analysis on their dataset again.</p>
<section id="pixi---environment-manager" class="level4">
<h4 class="anchored" data-anchor-id="pixi---environment-manager">Pixi - Environment manager</h4>
<ol type="1">
<li>To start, install pixie:<br>
<code>$curl -fsSL https://pixi.sh/install.sh | sh</code></li>
<li>Create a new project directory</li>
<li>Add conda-forge and bioconda channels using -c flag:<br>
<code>$pixi init folder_name -c conda-forge -c bioconda</code><br>

<p style="margin-left:2em;">
-&gt; Channels will give Pixi a source from were to install the dependencies. It’s like telling Pixi which shop to go to to buy all the tools you need.
</p></li>
<li>In your new folder you can now find a file - <strong>pixi.toml</strong>
<p style="margin-left:2em;">
-&gt; .toml contains all the important information about your environment. It tells you the channels you have added, the name you have given the environment, which operating system, in which version it has been optimized for. Here we can also define different tasks and a list of all the tools/dependencies that have been installed in this environment, after they have been added.
</p></li>
<li>To add a new tool/dependency you need to be in the project’s folder. Then you can simply use the command:<br>
<code>$pixi add Quarto</code><br>
e.g.&nbsp;to add Quarto
<p style="margin-left:2em;">
-&gt; to see if it was installed properly you can either test it with the command <code>$pixi run quarto --help</code>or go back to the .toml file and find that Quarto has been added as a dependency.
</p></li>
<li>No that you have added a tool, yet another file has been added to your project folder: pixi.lock.<br>

<p style="margin-left:2em;">
-&gt; .lock tracks everything pixi actually did to install your tool, the channels, where the packages were downloaded from, licences etc.
</p>
<strong>!OBS: DON’T EVER DELETE .toml OR .lock. THIS WILL CAUSE YOUR ENVIRONMENT TO BREAK!</strong></li>
<li>To use your tool you can use:<br>
<code>$pixi run quarto --help</code><br>
<strong>Pro-Tip:</strong> You can also enter the environment using <code>$pixi shell</code>. This allows you to forget about pixi and just run your commands as “normally” e.g.&nbsp;`$quarto –help. To leave it again, just type exit into the commandline and press enter.</li>
</ol>
</section>
<section id="container-images" class="level4">
<h4 class="anchored" data-anchor-id="container-images">Container images</h4>
<p>To ensure that your analysis are easily reproducible, indepentent of when and where they are run you can use container images. These are containers that have been created by other people. Here we are using Apptainer as a container, as it is already installed on the course server, however Docker was also recommended. Two common platforms to download container images from are Dockerhub and Seqera.</p>
<ol type="1">
<li>Dockerhub provides the first tool that we want to install: VCFtool, a software created for manipulation and quering of VCF files. It’s like a Swiss Army knife for VCF files - filter, summerize, analyze qenetic/sequencing data. To install it use:<br>
<code>$apptainer pull vcftools_0.1.16-1.sif docker://biocontainers/vcftools:v0.1.16-1-deb_cv1</code>
<p style="margin-left:2em;">
-&gt; apptainer is the software that is called, pull is the command to download/fetch something. “vcftools_0.1.16.1.sif” is the name of the container image. docker:// is te dockerhub registry that we are pulling our software from. “biocontainers/vcftools…” is the user profile that created the container and the name of the container you want to use.
</p></li>
<li>Another platform for container images is Seqera. This platform is a little different from dockerhub since it does not provide container images that have been uploaded by other users but rather they build them as you request them, by using bioconda, conda-forge and pypi. Thus, the software that you want to use has to be present in one of those reposetories. Change the Container settings on their website from Docker to Singularity and search for bioconda::vcftools=0.1.17.</li>
<li>Click on get Container, then copy paste the text from the website to the your system:<br>
<code>$apptainer pull fastqc:0.12.1.sif oras://community.wave.seqera.io/library/vcftools:0.1.17--b541aa8d9f9213f9</code>
<p style="margin-left:2em;">
oras is used, as this is the registry that is being pulled from in this case
</p>
Here, we are pulling from the oras registry rather then docker which is why we use oras:// isntead.</li>
<li>To run use: <code>$apptainer exec fastqc:0.12.1.sif vcftools --version</code></li>
</ol>


</section>

 ]]></description>
  <category>news</category>
  <guid>https://larissa-k-g.github.io/MedBioInfo-Blog/posts/pixi-environment-containers/</guid>
  <pubDate>Tue, 07 Oct 2025 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Quality control</title>
  <dc:creator>Larissa Kahnwald</dc:creator>
  <link>https://larissa-k-g.github.io/MedBioInfo-Blog/posts/Quality-control/</link>
  <description><![CDATA[ 





<p><img src="https://larissa-k-g.github.io/MedBioInfo-Blog/posts/Quality-control/DNA.jpg" class="img-fluid" style="float:right; width:45%; margin:0 0 1rem 1rem;"></p>
<p>Determining the quality of your data is key, in order to know if your result is trustworthy or not, should you actually be drawing any conlcusions from your experiment in the first place?<br>
Quaility control is therefore central, to get to know your data and to understand what you are working with. For sequencing data we can use the software FastQC to check the raw data, before starting a lengthy analysis.<br>
FastQC is especially valuable if we do high-thoughput sequencing and thus have a lot of data to juggle. A lot of data also means that analysis, might run for several hours, even on a supercomputer. To protect your session from being interupted due to connection issues or because the laptop is accidentally being closed; we can use GNU Screen, a terminal multiplexer. Screen enables to start several independant sessions and even to continue a running process if we disconnect. It basically creates virtual terminals inside our session. Another system we need is a job scheduler. SLURM is such a management system, meaning that it can start and control jobs for you. It is used in computer clusters to organize the queing of different jobs and SLURM also automatically substracts the running time from your project account. So, now that we have our job secured with a screen session and Slurm takes care of the resources we can move on to set the quality control.<br>
The best way to keep track of all the instructions is to define them in sequence in a script. To this end, create a new directory for all the scripts within our project folder and create a <em>.sh</em> file for our instructions. Since SLURM is our resoource management we use sbatch to submit a batch script.<br>
To do a quality control for your seqeuncing data you can use FastQC. FastQC is a tool, that is suitable for high-throughput sequencing data. It provides information on the general quality on your reads, visualizes the quiality score distribution, as well as the share of each base per sequence. Using FastQC will allow you to identify contaminations due to adapters or other sequences which are overrepresented. It will give you a quality score for an entire sample, instead of single reads. However, the output will still be one file per sample. Therefore, if you need to analyze several samples in one project you can use MultiQC to summerize the output from FastQC.</p>
<section id="screen-session" class="level4">
<h4 class="anchored" data-anchor-id="screen-session">Screen Session</h4>
<ol type="1">
<li>Start by naming a session<br>
<code>$screen -S name</code></li>
<li>Start your process, then detach from the screen any time and let it run independently. You can then log out or start toher screens and come back to this process at a later time.<br>
<code>Ctrl+ a d</code><br>
</li>
<li>Simply get a list of all open screen session:<br>
<code>$screen -ls</code><br>
Then, reattach to the selected session:<br>
<code>$screen -r name</code></li>
</ol>
</section>
<section id="fastqc" class="level4">
<h4 class="anchored" data-anchor-id="fastqc">FastQC</h4>
<ol type="1">
<li>Use Pixi to install FastQC or check if it has already been installed:<br>
</li>
</ol>
<ul>
<li>to check if it is installed: <code>$ pixi run fastqc --help</code></li>
<li>to install:<br>
<code>$pixi init -c conda-forge -c bioconda</code><br>
<code>$pixi add fastqc</code><br>
<code>$pixi run fastqc --help</code></li>
</ul>
</section>
<section id="multiqc" class="level4">
<h4 class="anchored" data-anchor-id="multiqc">MultiQC</h4>
<ol type="1">
<li>Use Pixi to install MultiQC or check if it has already been installed:<br>
</li>
</ol>
<ul>
<li>to check if it is installed fo into the pixi.toml or run <code>$pixi run multiqc --help</code></li>
<li>to install:<br>
<code>$pixi init -c conda-forge -c bioconda</code><br>
<code>$pixi add multiqc</code></li>
</ul>
<p>-&gt; To activate the environment run: <code>$pixi shell</code></p>
</section>
<section id="slurm" class="level4">
<h4 class="anchored" data-anchor-id="slurm">Slurm</h4>
<p>You can run Slurm from the command line using:<br>
<code>$srun -A project_ID -t dd-hh:mm:ss -n 1 &lt;tool options, commands and pathways to the dataset&gt;</code><br>
- The project_ID defines the project/account which is charged for the computing time. You can check the projects of which you are a member with <code>$projinfo</code>. This will also allow you to see how many computing hours are left on them.<br>
- ‘-t’ gives an estimate of the computing time that the job is going to need. This will not only influence the job queueing (shorter run times are preferred) but also defines the max time that will be spent on the task. After the given time the job will be cancelled.<br>
- to use e.g.&nbsp;FastQC on one or two samples we would define it like this: <code>$srun -A project_ID -t 15:00 -n 1 fastqc --noextract -o fastqc data/sample_1.fastq.gz data/sample_2.fastq.gz</code></p>
</section>
<section id="sbatch" class="level4">
<h4 class="anchored" data-anchor-id="sbatch">sbatch</h4>
<ol type="1">
<li>Create a new folder within your project folder and add a <code>name.sh</code> file for the batch script.</li>
<li>For FastQC set your file up like this:<br>
</li>
</ol>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb1-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#!/bin/bash -l </span></span>
<span id="cb1-2"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#SBATCH -A project_ID </span></span>
<span id="cb1-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#SBATCH -t dd-hh:mm:ss</span></span>
<span id="cb1-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#SBATCH -n 1 </span></span>
<span id="cb1-5"></span>
<span id="cb1-6"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">pixi</span> run fastqc <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-o</span> ../fastqc <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--noextract</span> ../data/<span class="pp" style="color: #AD0000;
background-color: null;
font-style: inherit;">*</span>fastq.gz</span></code></pre></div></div>
<p>2’. For MultiQC set it up like this</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb2-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#! /bin/bash -l</span></span>
<span id="cb2-2"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#SBATCH -A project_ID</span></span>
<span id="cb2-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#SBATCH -t dd-hh:mm:ss</span></span>
<span id="cb2-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#SBATCH -n 1</span></span>
<span id="cb2-5"></span>
<span id="cb2-6"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">pixi</span> run multiqc <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-o</span> ../multiqc ../fastqc</span></code></pre></div></div>
<ol start="3" type="1">
<li><p>Save the script and run it with pixi:<br>
<code>$pixi run sbatch name.sh</code><br>
</p>
<p style="margin-left:2em;">
</p><p>-&gt; you can verify that everything is running properly by checking your job’s status: <code>$ squeue -u &lt;user-name&gt;</code></p></li>
<li><p>When the job is completed you can find the output files in the same folder, where you where in, when you submitted the job. Per default FastQC and MultiQC will give out an .html file which you can download and open locally.</p></li>
</ol>


</section>

 ]]></description>
  <category>news</category>
  <guid>https://larissa-k-g.github.io/MedBioInfo-Blog/posts/Quality-control/</guid>
  <pubDate>Tue, 07 Oct 2025 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Getting started with a Quarto Blog</title>
  <dc:creator>Larissa Kahnwald</dc:creator>
  <link>https://larissa-k-g.github.io/MedBioInfo-Blog/posts/quarto-blogs/</link>
  <description><![CDATA[ 





<div class="quarto-figure quarto-figure-center" style="float:right; width:45%; margin:0 0 1rem 1rem;">
<figure class="figure">
<p><img src="https://larissa-k-g.github.io/MedBioInfo-Blog/posts/quarto-blogs/patrick-tomasso-Oaqk7qqNh_c-unsplash.jpg" class="img-fluid figure-img"></p>
<figcaption>Getting started</figcaption>
</figure>
</div>
<p>First, create a new folder for a new blog entry. Then create an index.qmd file within that folder. This is going to be where you insert your blog entery. You can add title, author, date and assign a category. There are more options howe Second, add your text and adjust the title etc. In short: make your entry. To check inbetween you can click the preview/rendering button next to the file name or press shift + command + K to get a preview of the updates you made in the webview.</p>
<strong>!Pro Tip: </strong>To make paragraphs end the line with two spaces.
<p style="margin-left:2em;">
For an indentation try <code>&lt;p style="margin-left:2em;"&gt; Your indented text &lt;/p&gt;</code>
</p>
<hr>
<p>To actually safe and publish go into the Terminal again and<br>
<code>$git add --all</code><br>
<code>$git commit -m "Remember to leave a little comment of what the changes that you made were"</code><br>
<code>$git push origin main</code><br>
In case of this error: “Updates were rejected because the remote contains work that you do hint: not have locally. This is usually caused by another repository pushing” try:<br>
<code>$git pull origin main</code> This should merge the remote updates with your local copy, then try push again.<br>
<code>$git push origin main</code>.</p>
<p>And there you go - Your first Quarto Blog Entry!</p>



 ]]></description>
  <category>news</category>
  <guid>https://larissa-k-g.github.io/MedBioInfo-Blog/posts/quarto-blogs/</guid>
  <pubDate>Mon, 06 Oct 2025 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Post With Code</title>
  <dc:creator>Harlow Malloc</dc:creator>
  <link>https://larissa-k-g.github.io/MedBioInfo-Blog/posts/post-with-code/</link>
  <description><![CDATA[ 





<p>executable code in quarto e.g.&nbsp;using bash needs a python or something environment, otherwise quarto doesn’t now how to execute it. This is a post with executable code.</p>



 ]]></description>
  <category>news</category>
  <category>code</category>
  <category>analysis</category>
  <guid>https://larissa-k-g.github.io/MedBioInfo-Blog/posts/post-with-code/</guid>
  <pubDate>Sun, 05 Oct 2025 00:00:00 GMT</pubDate>
  <media:content url="https://larissa-k-g.github.io/MedBioInfo-Blog/posts/post-with-code/image.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Welcome To My Blog</title>
  <dc:creator>Tristan O&#39;Malley</dc:creator>
  <link>https://larissa-k-g.github.io/MedBioInfo-Blog/posts/welcome/</link>
  <description><![CDATA[ 





<p>This is the first post in a Quarto blog. Welcome!</p>
<p><img src="https://larissa-k-g.github.io/MedBioInfo-Blog/posts/welcome/thumbnail.jpg" class="img-fluid"></p>
<p>Since this post doesn’t specify an explicit <code>image</code>, the first image in the post will be used in the listing page of posts.</p>



 ]]></description>
  <category>news</category>
  <guid>https://larissa-k-g.github.io/MedBioInfo-Blog/posts/welcome/</guid>
  <pubDate>Fri, 03 Oct 2025 00:00:00 GMT</pubDate>
</item>
</channel>
</rss>
